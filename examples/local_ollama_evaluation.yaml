# Local Evaluation Configuration using Ollama
# This example demonstrates privacy-first evaluation with local models

# Adapter configuration
adapters:
  default_adapter: local_ollama

  adapters:
    local_ollama:
      type: ollama
      base_url: http://localhost:11434
      default_model: llama3
      timeout: 120.0
      pull_missing_models: true  # Automatically download models if needed
      model_timeout: 180.0       # Extended timeout for model inference

      # Privacy-focused rate limiting (conservative for local)
      rate_limit:
        concurrent_requests: 3   # Limit concurrent requests to preserve resources
        burst_size: 5

      # Local-friendly retry configuration
      retry:
        max_retries: 2
        initial_delay: 2.0
        max_delay: 10.0
        exponential_base: 2.0
        jitter: false

# Template configuration
templates:
  system_prompt: |
    You are an AI assistant helping with code quality evaluation.
    Please provide objective, helpful feedback on the given code.

  user_prompt: |
    Please evaluate the following code for {{criteria}}:

    ```{{language}}
    {{code}}
    ```

    Focus on: {{focus_areas}}

    Provide your assessment with specific examples and suggestions.

# Schema definition for prompt variables
schema:
  criteria:
    type: categorical
    values:
      - "readability and maintainability"
      - "performance and efficiency"
      - "security best practices"
      - "error handling and robustness"
      - "code structure and organization"

  language:
    type: categorical
    values: ["python", "javascript", "java", "go", "rust", "typescript"]

  code:
    type: categorical
    values:
      - |
        def fibonacci(n):
            if n <= 1:
                return n
            return fibonacci(n-1) + fibonacci(n-2)
      - |
        function processData(data) {
          return data.map(item => item.value * 2).filter(x => x > 10);
        }
      - |
        public class Calculator {
            public int add(int a, int b) {
                return a + b;
            }
        }

  focus_areas:
    type: categorical
    values:
      - "algorithm efficiency"
      - "memory usage"
      - "error handling"
      - "code clarity"
      - "best practices"

# Sampling configuration
sampling:
  method: latin_hypercube
  sample_size: 25  # Smaller sample for local evaluation
  optimization:
    criterion: maximin
    iterations: 100

# Evaluation oracles
oracles:
  primary:
    type: llm_judge
    adapter: local_ollama
    model: llama3  # Use same local model for evaluation
    system_prompt: |
      You are a code quality expert. Rate the following code evaluation on a scale of 1-5 where:
      1 = Poor (major issues, unhelpful feedback)
      2 = Below Average (some issues, limited helpfulness)
      3 = Average (adequate feedback with room for improvement)
      4 = Good (helpful feedback with minor gaps)
      5 = Excellent (comprehensive, actionable feedback)

      Consider accuracy, completeness, and actionability of the feedback.

    prompt: |
      Original code:
      ```{{language}}
      {{code}}
      ```

      Evaluation criteria: {{criteria}}
      Focus areas: {{focus_areas}}

      AI Response:
      {{response}}

      Rate this evaluation (1-5) and explain your reasoning briefly.

# Analysis configuration
analysis:
  confidence_level: 0.95
  bayesian:
    prior_mean: 3.0    # Neutral prior for 1-5 scale
    prior_variance: 1.0
    mcmc:
      chains: 2        # Reduced for local processing
      samples: 1000    # Reduced samples for faster local analysis
      warmup: 200

# Output configuration
output:
  format: json
  include_raw_data: false  # Privacy: don't save raw responses
  metrics:
    - mean_score
    - confidence_interval
    - response_time
    - model_consistency

  privacy:
    redact_sensitive_data: true
    include_privacy_report: true
    log_data_retention: "session_only"

# Privacy and compliance settings
privacy:
  level: maximum
  data_retention: local_only
  external_calls: none
  logging:
    sanitize_requests: true
    redact_responses: false  # Keep full responses for analysis
    max_log_retention: "24h"

  compliance:
    gdpr_mode: true
    data_sovereignty: true
    audit_trail: minimal
